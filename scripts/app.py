"""
WildGaurd-Edge: Web Application for Fire Detection Model Testing
Allows you to upload and test audio files without hardware
"""

from flask import Flask, render_template, request, jsonify, send_from_directory
from flask_cors import CORS
import os
import json
import numpy as np
import librosa
from pathlib import Path
from datetime import datetime
import traceback
import requests

# Initialize Flask app
app = Flask(__name__)
CORS(app)  # Enable CORS for all routes
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024  # 50MB max file size

# Create upload folder
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# Configuration
CONFIG = {
    'sr': 16000,  # Sample rate
    'n_mfcc': 13,  # MFCC coefficients
}

# Load model metrics
MODEL_METRICS_PATH = Path('04_models/baseline/baseline_performance.json')
try:
    with open(MODEL_METRICS_PATH, 'r') as f:
        MODEL_METRICS = json.load(f)
except:
    MODEL_METRICS = None

# Store test results
test_results = []

# Edge Impulse Model Server URL
EI_MODEL_SERVER = 'http://localhost:5001'

def extract_features_for_ei_model(audio_path):
    """Extract features exactly as Edge Impulse expects them."""
    try:
        y, sr = librosa.load(audio_path, sr=CONFIG['sr'])
        
        # Extract MFCC (13 coefficients)
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CONFIG['n_mfcc'])
        mfcc_mean = np.mean(mfcc, axis=1)  # (13,)
        
        # Extract Mel-Frequency Energy
        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64)
        mel_energy = np.mean(mel_spec, axis=1)  # (64,) - use first 8
        
        # Combine features to match Edge Impulse model input
        # Total should match training: 13 MFCC + 8 additional = 21 features
        combined_features = np.concatenate([
            mfcc_mean,  # 13 features
            mel_energy[:8]  # 8 features from mel spectrum
        ])
        
        return combined_features.tolist(), True
    except Exception as e:
        print(f"Feature extraction error: {e}")
        return None, False


def predict_fire_with_ei_model(features):
    """Call Edge Impulse model via Node.js server for 98.92% accuracy."""
    try:
        # Call Node.js server
        response = requests.post(
            f'{EI_MODEL_SERVER}/api/predict',
            json={'features': features},
            timeout=5
        )
        
        if response.status_code == 200:
            result = response.json()
            if result['status'] == 'success':
                return (
                    result['prediction'],
                    result['confidence'],
                    result['prediction_text']
                )
        
        # If model server fails, fall back to feature-based
        print(f"Model server error: {response.status_code}")
        return None, None, None
    except Exception as e:
        print(f"Error calling Edge Impulse model: {e}")
        return None, None, None


def extract_mfcc_features(audio_path):
    """Extract MFCC features from audio file."""
    try:
        y, sr = librosa.load(audio_path, sr=CONFIG['sr'])
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CONFIG['n_mfcc'])
        features = np.mean(mfcc, axis=1)
        return features, True
    except Exception as e:
        return None, False


def predict_fire(features):
    """
    Improved fire detection using advanced MFCC analysis.
    Based on fire acoustic patterns:
    - High frequency crackling/popping (8-13kHz)
    - Rapid energy fluctuations
    - Broadband spectral content
    - Non-stationary patterns
    
    Returns: (prediction, confidence)
    """
    if features is None:
        return None, None
    
    try:
        # Extract comprehensive features
        mfcc_mean = np.mean(features)
        mfcc_std = np.std(features)
        mfcc_max = np.max(features)
        mfcc_min = np.min(features)
        mfcc_median = np.median(features)
        
        # Split into frequency bands
        bass = np.mean(np.abs(features[0:2]))        # Low freq (0-2)
        low_mid = np.mean(np.abs(features[2:4]))     # Low-mid (2-4)
        mid = np.mean(np.abs(features[4:7]))         # Mid (4-7)
        high = np.mean(np.abs(features[7:10]))       # High (7-10)
        ultra_high = np.mean(np.abs(features[10:]))  # Ultra high (10-13)
        
        # Energy characteristics
        total_energy = np.sum(np.abs(features))
        energy_variance = np.var(features)
        
        # Spectral spread
        freq_range = mfcc_max - mfcc_min
        
        # Fire detection score (weighted components)
        fire_score = 0.0
        
        # 1. HIGH FREQUENCY DOMINANCE (crackling is in high freq) - 25%
        high_freq_ratio = (high + ultra_high) / (mid + 0.001)
        if high_freq_ratio > 0.5:
            fire_score += 0.25 * min(high_freq_ratio / 2.0, 1.0)
        else:
            fire_score -= 0.1
        
        # 2. SPECTRAL VARIANCE (fire has irregular patterns) - 25%
        if mfcc_std > 0.8:
            fire_score += 0.25 * min(mfcc_std / 2.5, 1.0)
        elif mfcc_std > 0.5:
            fire_score += 0.15
        else:
            fire_score -= 0.05
        
        # 3. ENERGY VARIANCE (fire has fluctuating energy) - 20%
        if energy_variance > 0.5:
            fire_score += 0.20 * min(energy_variance / 2.0, 1.0)
        elif energy_variance > 0.2:
            fire_score += 0.10
        
        # 4. FREQUENCY SPREAD (fire covers wide spectrum) - 15%
        if freq_range > 1.5:
            fire_score += 0.15 * min(freq_range / 4.0, 1.0)
        elif freq_range > 1.0:
            fire_score += 0.08
        
        # 5. ENERGY PROFILE (fire has specific energy signature) - 15%
        # Not too low (background noise) and not too high (loud sound)
        if 0.5 < total_energy < 50:
            fire_score += 0.15
        elif 0.3 < total_energy < 100:
            fire_score += 0.08
        
        # Normalize confidence to 0-1
        confidence = min(max(fire_score, 0.0), 1.0)
        
        # Boost strong signals, dampen weak ones
        if confidence > 0.65:
            confidence = min(confidence * 1.1, 1.0)
        elif confidence > 0.45:
            confidence = min(confidence * 1.05, 1.0)
        elif confidence < 0.35:
            confidence = max(confidence * 0.8, 0.0)
        
        # Decision threshold (lower = more sensitive to fire)
        prediction = 1 if confidence > 0.45 else 0
        
        return prediction, confidence
        
    except Exception as e:
        print(f"Prediction error: {e}")
        return None, None


@app.route('/')
def index():
    """Home page."""
    return render_template('index.html')


@app.route('/api/model-info')
def model_info():
    """Get model information."""
    if MODEL_METRICS:
        return jsonify({
            'status': 'success',
            'accuracy': MODEL_METRICS.get('validation_metrics', {}).get('accuracy', 0),
            'fire_recall': MODEL_METRICS.get('fire_detection_analysis', {}).get('recall_fire', 0),
            'latency_ms': MODEL_METRICS.get('on_device_performance', {}).get('inferencing_time_ms', 0),
            'model_size_mb': MODEL_METRICS.get('on_device_performance', {}).get('flash_usage_mb', 0),
            'ready': True
        })
    return jsonify({'status': 'error', 'message': 'Model metrics not found', 'ready': False})


@app.route('/api/test-audio', methods=['POST'])
def test_audio():
    """Test audio file for fire detection using REAL Edge Impulse model (98.92% accuracy)."""
    global test_results
    
    try:
        # Check if file is present
        if 'file' not in request.files:
            return jsonify({'status': 'error', 'message': 'No file provided'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({'status': 'error', 'message': 'No file selected'}), 400
        
        # Save uploaded file
        filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{file.filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        # Extract features for Edge Impulse model
        features, success = extract_features_for_ei_model(filepath)
        
        if not success or features is None:
            os.remove(filepath)
            return jsonify({'status': 'error', 'message': 'Could not process audio file'}), 400
        
        # Try to use REAL Edge Impulse model first (98.92% accuracy!)
        prediction, confidence, prediction_text = predict_fire_with_ei_model(features)
        
        # If model server is unavailable, fall back to improved feature-based
        if prediction is None:
            print("âš ï¸  Edge Impulse model server not available, using fallback prediction")
            from app import predict_fire  # Import the feature-based predictor
            prediction, confidence = predict_fire(np.array(features))
            prediction_text = 'FIRE DETECTED ðŸ”¥' if prediction == 1 else 'NO FIRE âœ…'
        
        # Prepare result
        result = {
            'filename': file.filename,
            'timestamp': datetime.now().isoformat(),
            'prediction': prediction_text,
            'prediction_value': int(prediction),
            'confidence': float(confidence),
            'confidence_percent': f"{confidence*100:.1f}%",
            'model_type': 'Edge Impulse (98.92% accuracy)' if predict_fire_with_ei_model else 'Feature-based (improved)',
            'status': 'success'
        }
        
        # Store result
        test_results.append(result)
        
        # Cleanup
        os.remove(filepath)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/test-batch', methods=['POST'])
def test_batch():
    """Test multiple audio files."""
    global test_results
    
    try:
        data = request.get_json()
        audio_dir = data.get('directory', '')
        test_type = data.get('type', 'fire')  # 'fire' or 'non_fire'
        num_samples = int(data.get('samples', 10))
        
        if test_type == 'fire':
            base_path = Path('02_dataset/raw/audio_fire/fire')
        else:
            base_path = Path('02_dataset/raw/audio_non_fire')
        
        if not base_path.exists():
            return jsonify({'status': 'error', 'message': f'Directory not found: {base_path}'}), 400
        
        # Get audio files
        audio_files = list(base_path.glob('**/*.wav'))
        
        if len(audio_files) == 0:
            return jsonify({'status': 'error', 'message': 'No audio files found'}), 400
        
        # Sample files
        if len(audio_files) > num_samples:
            audio_files = np.random.choice(audio_files, num_samples, replace=False)
        
        results = []
        correct = 0
        
        for audio_file in audio_files[:num_samples]:
            try:
                features, success = extract_mfcc_features(str(audio_file))
                
                if not success:
                    continue
                
                prediction, confidence = predict_fire(features)
                
                if prediction is None:
                    continue
                
                # True label
                true_label = 1 if test_type == 'fire' else 0
                is_correct = (prediction == true_label)
                
                if is_correct:
                    correct += 1
                
                result = {
                    'filename': audio_file.name,
                    'prediction': 'FIRE' if prediction == 1 else 'NO FIRE',
                    'confidence': float(confidence),
                    'true_label': test_type,
                    'correct': is_correct
                }
                
                results.append(result)
            
            except Exception as e:
                continue
        
        accuracy = (correct / len(results) * 100) if results else 0
        
        return jsonify({
            'status': 'success',
            'test_type': test_type,
            'total_tested': len(results),
            'correct_predictions': correct,
            'accuracy': f"{accuracy:.1f}%",
            'results': results[:20]  # Return first 20 results
        })
    
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


@app.route('/api/results')
def get_results():
    """Get all test results."""
    return jsonify({
        'status': 'success',
        'total_tests': len(test_results),
        'results': test_results[-50:]  # Last 50 results
    })


@app.route('/api/clear-results', methods=['POST'])
def clear_results():
    """Clear all test results."""
    global test_results
    test_results = []
    return jsonify({'status': 'success', 'message': 'Results cleared'})


@app.route('/uploads/<filename>')
def download_file(filename):
    """Download uploaded file."""
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)


if __name__ == '__main__':
    print("\n" + "="*80)
    print("ðŸ”¥ WildGaurd-Edge: Web Application")
    print("="*80)
    print("\nâœ… Server starting...")
    print("ðŸ“± Open your browser: http://localhost:5000")
    print("\nFeatures:")
    print("  âœ“ Upload audio files for testing")
    print("  âœ“ Batch test fire/non-fire audio")
    print("  âœ“ See predictions with confidence scores")
    print("  âœ“ View all test results")
    print("\nPress Ctrl+C to stop the server")
    print("="*80 + "\n")
    
    app.run(debug=True, host='localhost', port=5000)
